caption_model: clipffprefixbert
noamopt: true
noamopt_warmup: 2000
label_smoothing: 0.0

# label
input_json: data/ucm_talk.json
input_label_h5: data/ucm_talk_label.h5

# sentence-level features
input_att_dir: /path/rsclip_feature_file
att_feat_size: 768

# class-level features
input_att_dir_rsi: data/ucmtalk_att
rsi_feat_size: 2048

# fusion
use_feat_fusion: True

# prefix
prefix_length: 5
use_prefix_feat: True
prefix_feat: rsclip

# pretained model
bert_premodel: data/bert-base-uncased # path to pretrained Bert

seq_per_img: 5
batch_size: 32
learning_rate: 0.0005

# Notice: because I'm to lazy, I reuse the option name for RNNs to set the hyperparameters for transformer:
# N=num_layers
# d_model=input_encoding_size
# d_ff=rnn_size

# will be ignored
num_layers: 6
input_encoding_size: 768
rnn_size: 2048

# Transformer config
#N_enc: 6
#N_dec: 6
#d_model: 512
#d_ff: 2048
num_att_heads: 8 # 8
dropout: 0.1

seed: 42
learning_rate_decay_start: 0
scheduled_sampling_start: 0  # -1
save_checkpoint_every: 25
#save_every_epoch: true
language_eval: 1
val_images_use: -1
max_epochs: 35
train_sample_n: 5

REFORWARD: false